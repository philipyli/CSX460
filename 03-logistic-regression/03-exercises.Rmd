---
title: "03-exercises"
author: "Phil Li"
date: "April 20, 2016"
output: html_document
---

## Readings

***APM***

- Chapter 4 "Over Fitting and Model Tuning"
- Chapter 12.2 "Logistic Regression""


## Miscellaneous

I am still struggling with names ...

- Please send me your picture
- [my photo here!](https://media.licdn.com/mpr/mpr/shrinknp_400_400/p/5/000/229/29f/3b94812.jpg)


## Assignment 

Note: The following will set-up your environment for this exercise. If you get an error stating that the packages have not been found, you need to install those packages.


```{r,echo=FALSE, warning=FALSE, message=FALSE}

packs <-  c('AppliedPredictiveModeling', 'ggplot2', 'magrittr', 'dplyr', 'caret')

for( nm in packs ) { 
  # message(nm)
  if( ! nm  %in% installed.packages()[,1]  ) install.packages(nm)
  library(nm, character.only = TRUE)
}

# Load data set into environment
data(FuelEconomy)     # See ?cars2010
fe <- dplyr::bind_rows(cars2010, cars2011, cars2012)    # Define Da


# data("GermanCredit")  # this is called later

... = NULL  # Needed for aesthetics 

```


## StepAIC


Using Fuel Economy data set from the **AppliedPredictiveModeling** Package.
- fit the simplest possible model using lm
- Use MASS::StepAIC to improve the model using forward stepwise regression

```{r}

library(MASS)

# AIC forward works by finding the input variable that reduces AIC most, 
# adding it, then repeating process until no further AIC reduction is possible
# (AIC is a measure of the tradeoff between model perfomance and complexity.)

stepAIC_fwd_wrapper <- function(outcome_var_name, dataset) {
  # start with a featureless model.  This is essentially just a mean of the outcome.
  # eval and parse allow lm to evaluate the variable whose name is contained in the string outcome_var_name
  fit_simplest <- lm(eval(parse(text = outcome_var_name)) ~ 1, dataset)  
  # take full list of variables in the fuel economy data, remove outcome variable to get predictors only
  dataset %>% names %>% setdiff(outcome_var_name) %>% paste(collapse=" + ") -> predictors_only
  
  # put outcome back together with predictors in formula 
  stepAIC_formula <- paste(outcome_var_name, "~", predictors_only)
  
  # stick formula into forward AIC
  stepAIC ( fit_simplest, scope = stepAIC_formula, direction = "forward")
}



step_fwd <- stepAIC_fwd_wrapper('FE', fe)

```


- Fit the "full" model using lm
- USe MASS::StepAIC to improve the model using backward stepwise regression 

```{r}

# AIC backwards is the opposite... put in all variables first... take one out at a time 
stepAIC_bkwd_wrapper <- function(outcome_var_name, dataset) {
  fit_full <- lm(FE ~ ., dataset)
  stepAIC(fit_full, scope = ~1, direction = "backward")
}



step_bkwd <- stepAIC_bkwd_wrapper('FE', fe)

```

- Are they the same model? If not why?  Which is better?
```{r}

# Of the 13 predictors, Forward selected 9 while Backward selected 11.  The models are very similar with nearly identical AIC and R-squared.
# forward AIC=3662.66       R-sq = 0.8190668
# backward AIC=3663.23       R-sq = 0.8197446
# 
# Let's try the loss functions from  the last homework

root_mean_sqr_error <- function(y,yhat) {
  ( y - yhat )^2  %>% mean %>% sqrt 
}

mean_abs_error <- function(y, yhat) {
  ( y - yhat )  %>% abs %>% mean
}

median_abs_error <- function(y, yhat) { 
  ( y - yhat )  %>% abs %>% median
}

root_mean_sqr_error(fe$FE, predict(step_fwd, fe))
mean_abs_error(fe$FE, predict(step_fwd, fe))
median_abs_error(fe$FE, predict(step_fwd, fe))

root_mean_sqr_error(fe$FE, predict(step_bkwd, fe))
mean_abs_error(fe$FE, predict(step_bkwd, fe))
median_abs_error(fe$FE, predict(step_bkwd, fe))

# StepAIC Backwards is a better model judging by all three loss functions, though again differences are minor.

```




## Logistic and Inverse Logistic Transformation 

- Write an R function for the logistic function. The function should accept a `numeric` vector with values `[-Inf,Inf]` and produce a numeric vector in the the range `[0,1]`.

- Plot the logistic function from  `[-10,10]`

- Write a R function for the inverse logistic function. The function should accept a `numeric` vector with values `[0,1]` and prodcuce a numeric vector in the range `[-Inf,Inf]`

- Plot the Inverse Logistic function from `[0,1]`


**Hint:** For plotting curves see `?graphics::curve` or `?ggplot2::stat_function`


```{r}

logistic <- function(x) { 
  1 / (1 + exp(1)^(-x) ) 
}

curve(logistic, from=-10, to=10)

logistic_inv <- function(y) { 
  - (log((1-y)/y))
}

curve(logistic_inv, from=0, to=1)

```

**NOTE"** These functions are quite handy, in evaluating logistic regression results. You may want to save these functions in your own package.  

```{r}
# DO NOT EDIT
c(-Inf,0,Inf) %>% logistic

c(0,0.5,1) %>% logistic_inv

```


## German Credit Model

Using the GermanCredit data from the **Caret** package/ UCI Machine Learning Library, create a model for `Class` ("Good" vs. "Bad" ). Show your model performance.  

```{r}

data(GermanCredit) 

# hmmm... I'll write a Step_AIC wrapper again here because the FE problem above takes lm, while this will require glm.  I'll write a common one some other time.

stepAIC_fwd_bi_wrapper <- function(outcome_var_name, dataset) {
  bi_fit_simplest <- glm(eval(parse(text = outcome_var_name)) ~ 1, dataset, family="binomial")  
  dataset %>% names %>% setdiff(outcome_var_name) %>% paste(collapse=" + ") -> predictors_only
  # put outcome back together with predictors in formula 
  stepAIC_formula <- paste(outcome_var_name, "~", predictors_only)
  # stick formula into forward AIC
  stepAIC ( bi_fit_simplest, scope = stepAIC_formula, direction = "forward")
}



GermanCreditFwd <- stepAIC_fwd_bi_wrapper('Class', GermanCredit)



stepAIC_bkwd_bi_wrapper <- function(outcome_var_name, dataset) {
  fit_full <- glm(Class ~ ., data=dataset, family="binomial")
  stepAIC(fit_full, scope = ~1, direction = "backward")
}



GermanCreditBkwd <- stepAIC_bkwd_bi_wrapper('Class', GermanCredit)



# This calcuates a simple accuracy rate... correct / all observations

accuracy_rate <- function(y,yhat) {
  ifelse(y==yhat, 1, 0) %>% mean 
}

good_or_bad <- function(yhat) {
  ifelse((logistic(yhat)>=.5), "Good", "Bad")
}



accuracy_rate(GermanCredit$Class, predict(GermanCreditFwd, GermanCredit) %>% good_or_bad)
accuracy_rate(GermanCredit$Class, predict(GermanCreditBkwd, GermanCredit) %>% good_or_bad)

# Again, the backward model is just a tiny bit better.  Our accuracy exceeds the baseline accuracy rate of 70 % on recommended by Kuhn p. 73.
```



## Iterative Correlated Feature Removal (Optional)

- Implement Kuhn's iterative feature removal function described in **APM** Section 3.5, page 47


```{r}
# 1. Calculate the correlation matrix of the predictors.
# 2. Determine the two predictors associated with the largest absolute pairwise correlation (call them predictors A and B).
# 3. Determine the average correlation between A and the other variables. Do the same for predictor B.
# 4. If A has a larger average correlation, remove it; otherwise, remove predictor B.
# 5. Repeat Steps 2â€“4 until no absolute correlations are above the threshold.

Kuhns_removal <- function(myData) {
  cor_matrix <- cor(myData[sapply(myData, is.numeric)])  # step 1
  
}

Kuhns_removal(fe)

```




## Synthetic Data (Optional)

Sometimes it is useful to "synthesize" feature data for to understand how a certain model behaves. 
Sythesize the following features 1000-element vectors: 

- x1: a normally distributed variable with `mean = 20` and standard deviation = 20 (`sd=8`).
- x2: a log-normally distributed feature with `meanlog = 1`, `sdlog=1.2`
- x3: a uniformly distributed feature with `min=0` and `max=50`. 

```{r}
nsamples = 20

x1 <- rnorm(nsamples,20,20)  
x2 <- rlnorm(nsamples, meanlog=1, sdlog = 1.2)
x3 <- runif(nsamples,0,50)

```

Next synthesis a response, `y` using the betas provided and an intercept that is normally distributed at 20 with standard deviation of 2. (**Hint:**  The betas thought of can be a vector or matrix)



```{r}

beta0 <- rnorm(nsamples,0,15)  # intercept!
beta1 <- 2.3
beta2 <- 4
beta3 <- 7

betas <- matrix( c(2.5, 4, 7), nrow=1  )  # 1x4 matrix

# x0 <- rep(1,nsamples) 

X  <- cbind(x1,x2,x3)  # 1000x4

y <- betas %*% t(X) %>% t
y <- y + beta0

qplot(y)
dat <- data.frame(y,X)

fit <- lm( y ~ . , dat )

coef(fit)

fit
```

- Did you recover the betas? 
- Is the model good?
- What happens if increase the value of `nsamples`? Decrease it?
- What transformations would you apply to x1? x2? x3? 

